{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61fd84f4",
   "metadata": {},
   "source": [
    "CRAWL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c213cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from Libraries.Crawler import CategoryValidator, UrlCollector, ArticleCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd79a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CÁC HÀM HỖ TRỢ ===\n",
    "\n",
    "def save_json(data, file_path):\n",
    "    \"\"\"Lưu một list dictionary vào file JSON.\"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Đọc dữ liệu từ file JSON.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def append_to_jsonl(data, file_path):\n",
    "    \"\"\"Ghi nối tiếp list dictionary vào file JSONL.\"\"\"\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "def get_existing_article_urls(file_path):\n",
    "    \"\"\"Lấy set các URL bài viết đã có từ file JSONL.\"\"\"\n",
    "    urls = set()\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    urls.add(json.loads(line)['url'])\n",
    "                except (json.JSONDecodeError, KeyError):\n",
    "                    continue\n",
    "    return urls\n",
    "\n",
    "def convert_to_xlsx(jsonl_path, xlsx_path):\n",
    "    \"\"\"Chuyển file JSONL sang XLSX.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_json(jsonl_path, lines=True)\n",
    "        column_order = [\"category\", \"sub_category\", \"url\", \"title\", \"description\", \"content\", \"date\", \"words\"]\n",
    "        df = df[[col for col in column_order if col in df.columns]]\n",
    "        df.to_excel(xlsx_path, index=False, engine='openpyxl')\n",
    "    except (FileNotFoundError, ValueError):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d84b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = load_json(\"Resource/categories.json\")\n",
    "\n",
    "my_config = {\n",
    "    \"BASE_URL\": \"https://vnexpress.net\",\n",
    "\n",
    "    \"MIN_YEAR\": 2020,\n",
    "    \"MIN_WORDS\": 200,\n",
    "    \"MAX_WORDS\": 1000,\n",
    "    \n",
    "    \"TARGET_ARTICLES_PER_SUBTYPE\": 30,\n",
    "    \"MAX_CONCURRENT_WORKERS\": 6,\n",
    "    \"VALIDATION_ARTICLES_COUNT\": 5,\n",
    "    \n",
    "    \"TYPE_DICT\": type_dict\n",
    "}\n",
    "\n",
    "resource_dir = \"Resource\"\n",
    "database_dir = \"Database\"\n",
    "pageName = \"VNExpress\"\n",
    "\n",
    "DICT_FILE = f\"{resource_dir}/{pageName}_DICT.json\"\n",
    "URLS_FILE = f\"{resource_dir}/{pageName}_URLS.json\"\n",
    "JSON_FILE = f\"{database_dir}/JSON/{pageName}.jsonl\"\n",
    "XLSX_FILE = f\"{database_dir}/XLSX/{pageName}.xlsx\"\n",
    "\n",
    "os.makedirs(resource_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(database_dir, \"JSON\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(database_dir, \"XLSX\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37c6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CHẠY QUY TRÌNH ===\n",
    "\n",
    "# --- Giai đoạn 1: Lấy danh sách chuyên mục hợp lệ ---\n",
    "validator = CategoryValidator(config=my_config)\n",
    "valid_categories = validator.run()\n",
    "save_json(valid_categories, DICT_FILE)\n",
    "\n",
    "# --- Giai đoạn 2: Thu thập URL ---\n",
    "validated_dict = load_json(DICT_FILE)\n",
    "if validated_dict:\n",
    "    url_collector = UrlCollector(config=my_config)\n",
    "    all_urls = url_collector.run(valid_subcategories=validated_dict)\n",
    "    save_json(all_urls, URLS_FILE)\n",
    "else:\n",
    "    print(\"Không có chuyên mục hợp lệ nào, dừng quy trình.\")\n",
    "\n",
    "# --- Giai đoạn 3: Crawl nội dung bài viết ---\n",
    "urls_to_crawl = load_json(URLS_FILE)\n",
    "if urls_to_crawl:\n",
    "    existing_urls = get_existing_article_urls(JSON_FILE)\n",
    "    \n",
    "    article_crawler = ArticleCrawler(config=my_config)\n",
    "    new_articles = article_crawler.run(\n",
    "        urls_to_crawl=urls_to_crawl, \n",
    "        existing_article_urls=existing_urls\n",
    "    )\n",
    "    \n",
    "    if new_articles:\n",
    "        append_to_jsonl(new_articles, JSON_FILE)\n",
    "        \n",
    "    convert_to_xlsx(JSON_FILE, XLSX_FILE)\n",
    "else:\n",
    "    print(\"Không có URL nào để crawl.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27fd100",
   "metadata": {},
   "source": [
    "TRAIN and TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa840550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from Libraries import Trainer\n",
    "\n",
    "training_config = {\n",
    "    # --- Đường dẫn và tên model ---\n",
    "    \"DATA_JSONL_FILE\": \"Database/JSON/vnexpress_articles.jsonl\",\n",
    "    \"MODEL_CHECKPOINT\": \"vinai/bartpho-syllable\",\n",
    "    \"OUTPUT_MODEL_DIR\": \"Models/bartpho-summarizer\",\n",
    "    \n",
    "    # --- Hyperparameters ---\n",
    "    \"MAX_INPUT_LENGTH\": 1024,\n",
    "    \"MAX_TARGET_LENGTH\": 256,\n",
    "    \"BATCH_SIZE\": 4,\n",
    "    \"NUM_TRAIN_EPOCHS\": 3,\n",
    "    \"LEARNING_RATE\": 3e-5,\n",
    "    \"WEIGHT_DECAY\": 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c4c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN ===\n",
    "summarizer_trainer = Trainer.SummarizationTrainer(config=training_config)\n",
    "summarizer_trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba83bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST ===\n",
    "fine_tuned_model_path = training_config[\"OUTPUT_MODEL_DIR\"] \n",
    "summarizer_pipeline = pipeline(\"summarization\", model=fine_tuned_model_path)\n",
    "\n",
    "# Lấy một bài báo từ dữ liệu của bạn để tóm tắt thử\n",
    "df = pd.read_json(training_config[\"DATA_JSONL_FILE\"], lines=True)\n",
    "sample_text = df.iloc[50][\"content\"] # Số 50\n",
    "\n",
    "print(\"--- VĂN BẢN GỐC ---\")\n",
    "print(sample_text)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"--- BẢN TÓM TẮT TỪ MODEL ---\")\n",
    "summary = summarizer_pipeline(sample_text, max_length=256, min_length=50, do_sample=False)\n",
    "print(summary[0]['summary_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
